{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): Identity()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "1.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "model_fp32 = models.resnet18(pretrained=True).to('cpu')\n",
    "#print(list(model_fp32.children()))\n",
    "\n",
    "model_fp32.eval()\n",
    "\n",
    "fused_model = torch.quantization.fuse_modules(model_fp32, [\n",
    "    ['conv1', 'bn1'], \n",
    "    ['layer1.0.conv1', 'layer1.0.bn1'],\n",
    "    ['layer1.0.conv2', 'layer1.0.bn2'],\n",
    "    ['layer1.1.conv1', 'layer1.1.bn1'],\n",
    "    ['layer1.1.conv2', 'layer1.1.bn2'],\n",
    "    ['layer2.0.conv1', 'layer2.0.bn1'],\n",
    "    ['layer2.0.conv2', 'layer2.0.bn2'],\n",
    "    ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
    "    ['layer2.1.conv1', 'layer2.1.bn1'],\n",
    "    ['layer2.1.conv2', 'layer2.1.bn2'],\n",
    "    ['layer3.0.conv1', 'layer3.0.bn1'],\n",
    "    ['layer3.0.conv2', 'layer3.0.bn2'],\n",
    "    ['layer3.0.downsample.0', 'layer3.0.downsample.1'],\n",
    "    ['layer3.1.conv1', 'layer3.1.bn1'],\n",
    "    ['layer3.1.conv2', 'layer3.1.bn2'],\n",
    "    ['layer4.0.conv1', 'layer4.0.bn1'],\n",
    "    ['layer4.0.conv2', 'layer4.0.bn2'],\n",
    "    ['layer4.0.downsample.0', 'layer4.0.downsample.1'],\n",
    "    ['layer4.1.conv1', 'layer4.1.bn1'],\n",
    "    ['layer4.1.conv2', 'layer4.1.bn2']\n",
    "], inplace=True)\n",
    "\n",
    "print(fused_model)\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(1:150528, 3:50176, 224:224, 224:1, requires_grad=0, device=cpu),\n",
      "      %conv1.weight : Float(64:147, 3:49, 7:7, 7:1, requires_grad=1, device=cpu),\n",
      "      %conv1.bias : Float(64:1, requires_grad=1, device=cpu),\n",
      "      %layer1.0.conv1.weight : Float(64:576, 64:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer1.0.conv1.bias : Float(64:1, requires_grad=1, device=cpu),\n",
      "      %layer1.0.conv2.weight : Float(64:576, 64:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer1.0.conv2.bias : Float(64:1, requires_grad=1, device=cpu),\n",
      "      %layer1.1.conv1.weight : Float(64:576, 64:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer1.1.conv1.bias : Float(64:1, requires_grad=1, device=cpu),\n",
      "      %layer1.1.conv2.weight : Float(64:576, 64:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer1.1.conv2.bias : Float(64:1, requires_grad=1, device=cpu),\n",
      "      %layer2.0.conv1.weight : Float(128:576, 64:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer2.0.conv1.bias : Float(128:1, requires_grad=1, device=cpu),\n",
      "      %layer2.0.conv2.weight : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer2.0.conv2.bias : Float(128:1, requires_grad=1, device=cpu),\n",
      "      %layer2.0.downsample.0.weight : Float(128:64, 64:1, 1:1, 1:1, requires_grad=1, device=cpu),\n",
      "      %layer2.0.downsample.0.bias : Float(128:1, requires_grad=1, device=cpu),\n",
      "      %layer2.1.conv1.weight : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer2.1.conv1.bias : Float(128:1, requires_grad=1, device=cpu),\n",
      "      %layer2.1.conv2.weight : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer2.1.conv2.bias : Float(128:1, requires_grad=1, device=cpu),\n",
      "      %layer3.0.conv1.weight : Float(256:1152, 128:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer3.0.conv1.bias : Float(256:1, requires_grad=1, device=cpu),\n",
      "      %layer3.0.conv2.weight : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer3.0.conv2.bias : Float(256:1, requires_grad=1, device=cpu),\n",
      "      %layer3.0.downsample.0.weight : Float(256:128, 128:1, 1:1, 1:1, requires_grad=1, device=cpu),\n",
      "      %layer3.0.downsample.0.bias : Float(256:1, requires_grad=1, device=cpu),\n",
      "      %layer3.1.conv1.weight : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer3.1.conv1.bias : Float(256:1, requires_grad=1, device=cpu),\n",
      "      %layer3.1.conv2.weight : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer3.1.conv2.bias : Float(256:1, requires_grad=1, device=cpu),\n",
      "      %layer4.0.conv1.weight : Float(512:2304, 256:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer4.0.conv1.bias : Float(512:1, requires_grad=1, device=cpu),\n",
      "      %layer4.0.conv2.weight : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer4.0.conv2.bias : Float(512:1, requires_grad=1, device=cpu),\n",
      "      %layer4.0.downsample.0.weight : Float(512:256, 256:1, 1:1, 1:1, requires_grad=1, device=cpu),\n",
      "      %layer4.0.downsample.0.bias : Float(512:1, requires_grad=1, device=cpu),\n",
      "      %layer4.1.conv1.weight : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer4.1.conv1.bias : Float(512:1, requires_grad=1, device=cpu),\n",
      "      %layer4.1.conv2.weight : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %layer4.1.conv2.bias : Float(512:1, requires_grad=1, device=cpu),\n",
      "      %fc.weight : Float(1000:512, 512:1, requires_grad=1, device=cpu),\n",
      "      %fc.bias : Float(1000:1, requires_grad=1, device=cpu)):\n",
      "  %43 : Float(1:802816, 64:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%input, %conv1.weight, %conv1.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %44 : Float(1:802816, 64:12544, 112:112, 112:1, requires_grad=1, device=cpu) = onnx::Relu(%43) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %45 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%44) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:586:0\n",
      "  %46 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%45, %layer1.0.conv1.weight, %layer1.0.conv1.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %47 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Relu(%46) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %48 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%47, %layer1.0.conv2.weight, %layer1.0.conv2.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %49 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Add(%48, %45)\n",
      "  %50 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Relu(%49) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %51 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%50, %layer1.1.conv1.weight, %layer1.1.conv1.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %52 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Relu(%51) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %53 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%52, %layer1.1.conv2.weight, %layer1.1.conv2.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %54 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Add(%53, %50)\n",
      "  %55 : Float(1:200704, 64:3136, 56:56, 56:1, requires_grad=1, device=cpu) = onnx::Relu(%54) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %56 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%55, %layer2.0.conv1.weight, %layer2.0.conv1.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %57 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Relu(%56) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %58 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%57, %layer2.0.conv2.weight, %layer2.0.conv2.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %59 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%55, %layer2.0.downsample.0.weight, %layer2.0.downsample.0.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %60 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Add(%58, %59)\n",
      "  %61 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Relu(%60) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %62 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%61, %layer2.1.conv1.weight, %layer2.1.conv1.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %63 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Relu(%62) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %64 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%63, %layer2.1.conv2.weight, %layer2.1.conv2.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %65 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Add(%64, %61)\n",
      "  %66 : Float(1:100352, 128:784, 28:28, 28:1, requires_grad=1, device=cpu) = onnx::Relu(%65) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %67 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%66, %layer3.0.conv1.weight, %layer3.0.conv1.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %68 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Relu(%67) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %69 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%68, %layer3.0.conv2.weight, %layer3.0.conv2.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %70 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%66, %layer3.0.downsample.0.weight, %layer3.0.downsample.0.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %71 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Add(%69, %70)\n",
      "  %72 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Relu(%71) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %73 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%72, %layer3.1.conv1.weight, %layer3.1.conv1.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %74 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Relu(%73) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %75 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%74, %layer3.1.conv2.weight, %layer3.1.conv2.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %76 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Add(%75, %72)\n",
      "  %77 : Float(1:50176, 256:196, 14:14, 14:1, requires_grad=1, device=cpu) = onnx::Relu(%76) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %78 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%77, %layer4.0.conv1.weight, %layer4.0.conv1.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %79 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Relu(%78) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %80 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%79, %layer4.0.conv2.weight, %layer4.0.conv2.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %81 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%77, %layer4.0.downsample.0.weight, %layer4.0.downsample.0.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %82 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Add(%80, %81)\n",
      "  %83 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Relu(%82) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %84 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%83, %layer4.1.conv1.weight, %layer4.1.conv1.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %85 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Relu(%84) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %86 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%85, %layer4.1.conv2.weight, %layer4.1.conv2.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %87 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Add(%86, %83)\n",
      "  %88 : Float(1:25088, 512:49, 7:7, 7:1, requires_grad=1, device=cpu) = onnx::Relu(%87) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %89 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%88) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:936:0\n",
      "  %90 : Float(1:512, 512:1, requires_grad=1, device=cpu) = onnx::Flatten[axis=1](%89) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torchvision\\models\\resnet.py:214:0\n",
      "  %output : Float(1:1000, 1000:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%90, %fc.weight, %fc.bias) # C:\\Users\\fukushima\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1690:0\n",
      "  return (%output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SAVE MODEL AS ONNX\n",
    "import torch\n",
    "dummy_input=torch.randn(1, 3,224,224)\n",
    "input_names = [ \"input\"]\n",
    "output_names = [ \"output\" ]\n",
    "\n",
    "torch.onnx.export(fused_model, dummy_input, \"./resnet18_fusedmodel.onnx\", verbose=True,input_names=input_names,output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011967400000003181\n",
      "1 / 0\n",
      "0.008732799999961571\n",
      "0.007237199999963195\n",
      "0.00921520000019882\n",
      "0.010925100000122256\n",
      "0.011676200000010795\n",
      "0.010943900000029316\n",
      "0.00959370000009585\n",
      "0.013730699999996432\n",
      "0.011224300000094445\n",
      "TOP1 ACCURACY: 9 / 1000\n",
      "TOP5 ACCURACY: 10 / 1000\n",
      "INVALID DATA: 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class_index = json.load(open('imagenet_class_index.json', 'r'))\n",
    "\n",
    "correct_top1 = 0\n",
    "correct_top5 = 0\n",
    "invalid = 0\n",
    "invalid_wnid = []\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "def my_preprocess(filename):\n",
    "    img = Image.open(filename)\n",
    "    h, w = img.size\n",
    "    if h > w:\n",
    "        img = img.resize((256 * h // w , 256))\n",
    "    else:\n",
    "        img = img.resize((256 , 256 * w // h))\n",
    "    h, w = img.size\n",
    "    img = img.crop(( (h-224)/2, (w-224)/2, 224+(h-224)/2, 224+(w-224)/2))\n",
    "    np_img = np.array(img)\n",
    "    np_img = np_img / 255\n",
    "    return (np_img - np.array([0.485, 0.456, 0.406]) ) / np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "fused_model.eval()\n",
    "for index in range(1000):\n",
    "    file = './Imagenet/' + str(index) + '.jpg'\n",
    "    try:\n",
    "        img = Image.open(file)\n",
    "        img_tensor = preprocess(img)\n",
    "        \n",
    "        #img = my_preprocess(file)\n",
    "        #img = img.transpose(2,0,1)\n",
    "        #img_tensor = torch.from_numpy(img.astype(np.float32)).clone()\n",
    "        \n",
    "        img_tensor.unsqueeze_(0)\n",
    "\n",
    "        outputs = fused_model(Variable(img_tensor).to('cpu'))\n",
    "\n",
    "        softmax = torch.nn.Softmax(dim=1)\n",
    "        softmax_out = softmax(outputs)\n",
    "\n",
    "        for i in range(5):\n",
    "            imagenet_key = str(softmax_out.topk(5)[1][0][i].item())\n",
    "            if imagenet_key == str(index):\n",
    "                if i == 0:\n",
    "                    correct_top1 += 1\n",
    "                correct_top5 += 1\n",
    "        if index % 10 == 0:\n",
    "            print(str(correct_top5) + ' / ' + str(index))\n",
    "    except:\n",
    "        invalid += 1\n",
    "        #print(class_index[str(index)][0])\n",
    "        invalid_wnid.append(class_index[str(index)][0])\n",
    "\n",
    "print('TOP1 ACCURACY: ' + str(correct_top1) + ' / ' + str(1000-invalid))\n",
    "print('TOP5 ACCURACY: ' + str(correct_top5) + ' / ' + str(1000-invalid))\n",
    "print('INVALID DATA: ' + str(invalid))\n",
    "print(invalid_wnid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight                       : [64  3  7  7],  max=0.39387545  min=-0.30834106\n",
      "\n",
      "conv1.bias                         : [64],  max=0.69328916  min=-0.64016706\n",
      "\n",
      "layer1.0.conv1.weight              : [64 64  3  3],  max=0.33263963  min=-0.37450415\n",
      "\n",
      "layer1.0.conv1.bias                : [64],  max=1.1022106  min=-0.8196391\n",
      "\n",
      "layer1.0.conv2.weight              : [64 64  3  3],  max=0.52512556  min=-0.77078116\n",
      "\n",
      "layer1.0.conv2.bias                : [64],  max=1.7853346  min=-1.2511991\n",
      "\n",
      "layer1.1.conv1.weight              : [64 64  3  3],  max=0.27995738  min=-0.26628444\n",
      "\n",
      "layer1.1.conv1.bias                : [64],  max=1.2079195  min=-1.0184617\n",
      "\n",
      "layer1.1.conv2.weight              : [64 64  3  3],  max=0.7608536  min=-1.0473908\n",
      "\n",
      "layer1.1.conv2.bias                : [64],  max=1.0843931  min=-1.1705731\n",
      "\n",
      "layer2.0.conv1.weight              : [128  64   3   3],  max=0.21269578  min=-0.14254896\n",
      "\n",
      "layer2.0.conv1.bias                : [128],  max=0.74007654  min=-0.43975008\n",
      "\n",
      "layer2.0.conv2.weight              : [128 128   3   3],  max=0.72415024  min=-0.48518723\n",
      "\n",
      "layer2.0.conv2.bias                : [128],  max=1.4463481  min=-0.7422414\n",
      "\n",
      "layer2.0.downsample.0.weight       : [128  64   1   1],  max=0.69225085  min=-0.56773424\n",
      "\n",
      "layer2.0.downsample.0.bias         : [128],  max=0.9656664  min=-1.1103511\n",
      "\n",
      "layer2.1.conv1.weight              : [128 128   3   3],  max=0.31105062  min=-0.25678483\n",
      "\n",
      "layer2.1.conv1.bias                : [128],  max=0.6169573  min=-0.8257396\n",
      "\n",
      "layer2.1.conv2.weight              : [128 128   3   3],  max=0.61107737  min=-0.8770784\n",
      "\n",
      "layer2.1.conv2.bias                : [128],  max=1.1592387  min=-1.1433209\n",
      "\n",
      "layer3.0.conv1.weight              : [256 128   3   3],  max=0.23571737  min=-0.18603379\n",
      "\n",
      "layer3.0.conv1.bias                : [256],  max=0.861289  min=-0.6855632\n",
      "\n",
      "layer3.0.conv2.weight              : [256 256   3   3],  max=0.5639192  min=-0.37700403\n",
      "\n",
      "layer3.0.conv2.bias                : [256],  max=0.60914946  min=-0.36932456\n",
      "\n",
      "layer3.0.downsample.0.weight       : [256 128   1   1],  max=0.3219906  min=-0.40816122\n",
      "\n",
      "layer3.0.downsample.0.bias         : [256],  max=0.23945019  min=-0.3355441\n",
      "\n",
      "layer3.1.conv1.weight              : [256 256   3   3],  max=0.27238303  min=-0.22437853\n",
      "\n",
      "layer3.1.conv1.bias                : [256],  max=0.74373055  min=-0.8067159\n",
      "\n",
      "layer3.1.conv2.weight              : [256 256   3   3],  max=0.7278896  min=-0.97012097\n",
      "\n",
      "layer3.1.conv2.bias                : [256],  max=1.0610821  min=-1.0131435\n",
      "\n",
      "layer4.0.conv1.weight              : [512 256   3   3],  max=0.30162284  min=-0.15277155\n",
      "\n",
      "layer4.0.conv1.bias                : [512],  max=0.56426764  min=-0.4788988\n",
      "\n",
      "layer4.0.conv2.weight              : [512 512   3   3],  max=1.1437747  min=-0.6911644\n",
      "\n",
      "layer4.0.conv2.bias                : [512],  max=0.74594164  min=-1.125592\n",
      "\n",
      "layer4.0.downsample.0.weight       : [512 256   1   1],  max=0.9982081  min=-0.83285093\n",
      "\n",
      "layer4.0.downsample.0.bias         : [512],  max=0.26464486  min=-0.75995487\n",
      "\n",
      "layer4.1.conv1.weight              : [512 512   3   3],  max=0.29326272  min=-0.17658025\n",
      "\n",
      "layer4.1.conv1.bias                : [512],  max=0.50997746  min=-0.85116595\n",
      "\n",
      "layer4.1.conv2.weight              : [512 512   3   3],  max=3.648308  min=-2.3268917\n",
      "\n",
      "layer4.1.conv2.bias                : [512],  max=2.225013  min=-0.6991796\n",
      "\n",
      "fc.weight                          : [1000  512],  max=0.71523696  min=-0.27785522\n",
      "\n",
      "fc.bias                            : [1000],  max=0.061649736  min=-0.049573567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SHOW MODEL PARAMS\n",
    "import numpy as np\n",
    "for key in fused_model.state_dict():\n",
    "    print(key.ljust(35), end=': ')\n",
    "    print(np.array(fused_model.state_dict()[key].shape), end=',  max=')\n",
    "    print( max(np.ravel(np.array(fused_model.state_dict()[key]))), end='  min=')\n",
    "    print( min(np.ravel(np.array(fused_model.state_dict()[key]))))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "conv1.bias\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.conv1.bias\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.conv2.bias\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.conv1.bias\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.conv2.bias\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.conv1.bias\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.conv2.bias\n",
      "layer2.0.downsample.0.weight\n",
      "layer2.0.downsample.0.bias\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.conv1.bias\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.conv2.bias\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.conv1.bias\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.conv2.bias\n",
      "layer3.0.downsample.0.weight\n",
      "layer3.0.downsample.0.bias\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.conv1.bias\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.conv2.bias\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.conv1.bias\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.conv2.bias\n",
      "layer4.0.downsample.0.weight\n",
      "layer4.0.downsample.0.bias\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.conv1.bias\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.conv2.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for key in fused_model.state_dict():\n",
    "    print(key)\n",
    "    np.savetxt('./resnet18_param/'+key+'.txt', np.ravel(np.array(fused_model.state_dict()[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): Identity()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# REMOVE LAST LAYER FROM MODEL\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "remove_layer = 1\n",
    "\n",
    "modules = list(fused_model.children())[:-remove_layer]\n",
    "check_model = nn.Sequential(*modules)\n",
    "#check_model = fused_model\n",
    "\n",
    "print(check_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 0.08890819549560547\n",
      "torch.Size([1, 1000])\n",
      "tensor([[ 4.8389e+00,  2.0648e+01, -7.9396e-01,  1.6835e+00,  3.2860e+00,\n",
      "          3.8289e+00,  3.3749e+00,  4.6865e+00,  3.4357e+00, -3.1508e+00,\n",
      "          2.7219e+00,  2.0141e+00,  4.9674e+00, -1.9659e-01,  2.5462e+00,\n",
      "          3.9514e+00,  1.0493e+00,  1.3478e+00, -1.9551e+00,  1.4296e-01,\n",
      "         -6.3565e-02,  1.5156e+00, -1.8726e+00, -1.7927e-01, -1.8498e+00,\n",
      "          7.3188e+00,  1.4851e+01,  1.7775e+01,  6.8965e+00,  1.6232e+01,\n",
      "          4.2191e+00,  8.4351e+00,  9.0231e+00,  4.7880e+00,  3.6737e+00,\n",
      "          5.1464e+00,  5.3828e+00,  3.0542e+00,  9.8607e+00,  3.7158e+00,\n",
      "          1.0031e+01,  6.6635e+00,  1.2615e+01,  6.7393e+00,  7.8229e+00,\n",
      "          3.1481e+00,  8.2788e+00,  5.9477e+00,  3.5756e+00,  4.9702e+00,\n",
      "          3.5887e+00,  1.7237e+00,  7.7454e+00,  5.6308e+00,  5.2948e+00,\n",
      "          3.9757e+00,  4.9697e+00,  3.3797e+00,  4.9800e+00,  5.3257e+00,\n",
      "          5.9610e+00,  5.5498e+00,  4.3237e+00,  4.6241e+00,  3.1754e+00,\n",
      "          5.1633e+00,  7.4550e+00,  4.1949e+00,  5.1173e+00,  5.0964e-01,\n",
      "          3.4558e+00,  4.8078e+00, -1.2766e+00,  1.6605e+00,  1.1589e+00,\n",
      "          4.3526e-04,  3.2226e+00,  2.3299e+00,  9.8837e-01,  4.3548e+00,\n",
      "          1.6613e+00,  4.4392e+00,  3.8913e+00,  1.0206e+00, -1.3503e-01,\n",
      "          1.8229e+00,  4.4454e+00,  1.3689e+00,  6.3376e+00,  3.5892e+00,\n",
      "          8.2518e+00,  3.5546e+00,  2.9753e+00,  2.0844e+00,  6.8542e+00,\n",
      "          2.4902e+00,  4.5881e+00,  2.2339e-01,  1.6665e+00,  2.5771e+00,\n",
      "          2.0069e+00, -5.4626e+00, -2.4671e-01,  6.6058e+00, -4.8597e-01,\n",
      "         -6.1150e-01, -8.7036e-01,  3.8500e+00,  7.9243e+00,  4.6065e+00,\n",
      "          8.5640e+00,  4.7889e+00,  8.4506e+00,  7.7293e+00,  1.1290e+01,\n",
      "          1.1782e+01,  6.4492e+00,  1.5956e+00,  3.4379e+00,  6.4810e+00,\n",
      "          7.6005e+00,  3.7846e+00,  6.7258e+00,  3.8122e+00,  7.4086e+00,\n",
      "          5.6323e+00,  7.0188e+00, -1.1728e+00, -7.5767e-01,  3.5852e+00,\n",
      "          7.0822e+00, -5.3392e-02,  3.7117e+00,  1.5887e+00,  1.6182e+00,\n",
      "         -8.8345e-02,  1.6012e+00, -4.4864e+00, -5.6789e-01,  1.2498e-01,\n",
      "          1.0504e-01,  2.9528e+00, -1.3810e+00,  1.2841e+00,  2.2148e+00,\n",
      "          2.1801e+00, -6.2335e-01, -5.5514e-01, -4.2107e+00,  2.7859e-01,\n",
      "          8.4695e-01,  3.1786e+00, -1.6553e+00, -1.4353e+00, -2.0963e+00,\n",
      "         -4.0745e+00, -2.5500e+00, -1.0839e+00, -1.0442e-01, -2.5776e+00,\n",
      "         -2.9722e+00, -3.3919e+00, -4.1219e+00, -2.5259e+00, -4.5679e+00,\n",
      "         -3.5225e+00, -3.1379e+00, -3.1362e+00,  3.6911e-01, -3.1923e+00,\n",
      "         -4.7007e+00,  6.3527e-01, -2.6245e+00, -1.2912e-01, -2.8040e+00,\n",
      "         -3.1651e+00, -2.2116e+00, -2.7532e+00, -2.5585e+00, -1.8730e+00,\n",
      "         -1.3801e+00,  2.7912e-01, -3.4685e+00, -3.7994e-01, -1.4614e-01,\n",
      "         -2.3930e+00,  1.0671e+00,  9.1369e-01, -7.5121e-01, -7.3729e-01,\n",
      "         -3.3421e+00, -9.1744e-01, -2.6319e+00, -6.8502e-02, -2.8572e+00,\n",
      "         -2.2249e+00, -3.6798e+00, -5.6694e+00, -5.1967e+00, -1.4206e+00,\n",
      "         -3.5923e+00, -2.0676e+00, -4.1536e+00,  1.1408e-01, -1.8755e+00,\n",
      "         -3.4935e+00, -2.0989e+00,  6.2433e-01, -1.7782e+00, -2.5381e+00,\n",
      "         -4.1555e+00,  1.5468e+00, -2.4053e+00, -1.7012e-01, -5.7701e-01,\n",
      "         -2.3228e+00, -3.3693e+00, -5.4880e+00, -3.8763e+00, -2.1085e+00,\n",
      "         -3.0207e+00, -2.2916e+00, -3.1326e+00, -2.9346e-01, -1.5352e-01,\n",
      "         -2.2290e+00, -4.9201e+00, -3.1356e+00, -3.8429e+00, -4.9545e+00,\n",
      "         -3.5727e+00, -2.0856e+00, -3.6930e+00, -3.5048e+00, -1.9872e+00,\n",
      "         -3.5780e+00, -1.1662e+00,  8.9505e-01, -3.9310e+00, -4.1972e+00,\n",
      "         -3.8650e+00, -3.9289e+00, -3.1676e+00, -2.8010e+00, -4.3704e+00,\n",
      "         -1.3292e+00, -2.6465e+00, -6.5397e+00, -3.3412e+00, -5.6033e+00,\n",
      "         -2.3900e+00, -1.9808e+00, -2.4211e+00,  1.2275e+00, -1.7226e+00,\n",
      "         -4.3964e+00, -4.1287e+00, -5.6651e+00,  4.2054e-01,  1.1522e+00,\n",
      "         -6.1581e-02, -3.3458e+00, -1.7468e+00, -9.7576e-01, -2.3614e+00,\n",
      "         -1.9081e-01, -7.4616e-01, -2.2632e+00, -2.1583e+00, -2.7526e+00,\n",
      "         -8.9525e-01, -5.9670e-01, -3.4896e-01,  1.8855e+00, -1.9397e-01,\n",
      "         -5.5940e+00, -1.9335e+00,  3.2958e+00,  1.0094e+00,  8.8719e-01,\n",
      "          2.5468e+00,  1.3599e+00,  9.6656e-01, -1.2815e+00, -2.2576e+00,\n",
      "          5.4296e-01, -2.7210e-01, -7.4687e-01,  4.6824e-01, -1.8028e+00,\n",
      "         -1.4225e+00, -3.3380e+00, -1.4512e+00, -4.0904e+00, -3.1941e+00,\n",
      "         -2.8058e+00,  1.9468e+00, -5.5001e+00,  6.0840e+00,  1.6676e+00,\n",
      "          3.5483e-01,  7.7319e+00,  2.3696e+00,  3.7866e+00,  5.2626e+00,\n",
      "          2.0717e-01,  2.9134e+00,  5.2754e+00,  1.1469e+00,  5.0757e+00,\n",
      "          5.8755e+00,  2.5173e+00,  1.8625e+00,  2.0472e+00,  6.1022e+00,\n",
      "          3.7748e+00,  4.4230e+00,  7.0159e+00,  2.5081e+00,  1.3155e+00,\n",
      "          2.3948e+00,  4.7585e+00,  4.4746e+00,  2.5866e+00,  2.2141e+00,\n",
      "          5.3165e+00,  4.6917e+00,  1.0656e+01,  1.7749e+00,  9.5711e+00,\n",
      "          3.0622e+00,  4.5501e-01, -5.5116e-01,  4.5863e+00, -1.1912e+00,\n",
      "          3.5422e+00,  1.2475e+00,  1.8260e+00,  3.4938e+00, -3.0379e+00,\n",
      "         -4.5933e+00,  7.0322e-01, -5.8943e-01, -4.2587e+00, -3.4203e+00,\n",
      "         -3.4592e+00, -4.6554e+00, -6.2301e+00, -3.3986e+00, -5.2739e+00,\n",
      "         -4.8329e-01, -3.5744e+00, -1.3189e+00, -1.6376e+00, -7.4099e+00,\n",
      "         -3.7515e+00,  4.7175e+00,  1.0599e+00, -4.3821e-01, -3.1485e-01,\n",
      "         -5.1470e-01, -3.7872e-01, -2.4606e+00, -1.8802e-01, -2.8376e+00,\n",
      "         -3.2072e+00, -6.0816e+00, -7.1440e+00, -3.0878e+00, -4.1672e+00,\n",
      "         -2.9227e+00, -4.3270e-01, -2.0916e+00, -6.7099e-01,  2.0655e+00,\n",
      "         -1.7158e+00,  2.7950e+00,  5.0044e+00, -1.3526e+00, -7.9573e-01,\n",
      "          4.5546e+00, -1.9059e+00,  6.6313e-01, -3.4739e+00,  4.9677e-01,\n",
      "         -4.9104e+00, -4.6234e+00,  1.9149e+00, -3.9385e+00,  3.6435e+00,\n",
      "          1.0044e+01,  6.0667e+00,  9.1505e+00,  8.9624e+00,  3.2231e+00,\n",
      "          6.3315e+00,  4.9324e+00,  4.5105e+00, -4.0918e+00, -1.3011e+00,\n",
      "         -1.1158e+00, -3.7520e+00, -3.5183e+00, -5.0829e+00, -2.1890e+00,\n",
      "          1.4727e+00, -1.8229e-01, -7.3815e-01, -4.3776e+00, -1.5090e+00,\n",
      "          1.4091e+00, -2.0340e+00, -5.4253e-01,  3.8546e-01, -1.6020e+00,\n",
      "         -2.9266e+00, -2.3677e-01, -2.6653e+00,  1.3421e+00,  2.4072e+00,\n",
      "         -2.9957e+00, -1.1034e+00, -3.0094e+00, -4.0468e+00, -4.9994e+00,\n",
      "         -5.6037e-01, -3.1305e+00, -1.5806e+00,  3.1709e+00, -1.4954e+00,\n",
      "         -2.7790e+00, -1.5412e+00, -1.6853e+00,  1.7678e+00,  4.5971e-01,\n",
      "          8.1175e-01, -3.2500e+00,  1.4229e+00, -1.0764e+00, -2.3059e+00,\n",
      "          1.4852e+00,  1.0440e+00, -2.5134e+00, -6.8655e-01, -4.8216e+00,\n",
      "         -2.3836e+00,  8.8405e-01, -1.7649e+00,  8.4942e-01, -1.6695e+00,\n",
      "         -2.9053e+00, -1.3660e+00,  9.2720e-01, -2.0597e+00, -3.2834e+00,\n",
      "          2.7351e+00,  1.4603e+00, -6.0945e-01, -5.4308e-01, -2.8468e+00,\n",
      "         -1.4022e+00, -4.0789e+00, -3.5995e-01,  3.5942e+00, -2.2345e-01,\n",
      "         -1.9662e+00, -3.8993e+00, -5.8265e-01, -3.7388e+00,  2.1996e-01,\n",
      "          1.1971e+00, -2.8238e+00, -9.9563e-02,  2.1643e+00, -1.2559e-01,\n",
      "         -4.1943e+00, -3.0010e+00, -5.2302e-01, -1.3095e+00, -1.5780e+00,\n",
      "         -1.8250e+00,  4.5979e-01, -3.0891e+00,  5.6736e-01, -2.1212e+00,\n",
      "         -3.9453e+00, -1.4194e+00,  1.6563e-02, -8.2541e-02,  1.5915e+00,\n",
      "         -1.3287e+00,  1.6380e+00, -9.5146e-01, -1.1390e+00, -1.1697e+00,\n",
      "         -2.9714e+00,  1.5040e+00, -1.2591e+00, -4.8225e+00,  1.6805e+00,\n",
      "         -2.5338e+00, -5.7275e-01,  1.6709e+00, -4.4733e-01,  7.0426e-01,\n",
      "         -4.2653e-01, -8.4318e-01, -2.4352e+00,  1.6881e+00,  2.3828e-01,\n",
      "         -3.0832e+00, -4.6673e+00,  6.0137e-01, -3.3665e+00, -1.5118e+00,\n",
      "         -1.1812e+00, -1.5510e+00, -1.8862e+00, -2.0144e+00, -3.3335e+00,\n",
      "         -2.8963e+00,  2.1961e+00, -1.9108e+00, -5.9358e-01, -2.6036e+00,\n",
      "         -2.2457e+00, -2.4490e+00, -1.6567e+00, -2.9035e+00, -6.4443e-01,\n",
      "         -1.0519e+00, -5.9197e-01, -2.2543e+00, -1.0071e+00, -7.5337e-01,\n",
      "         -1.5131e+00, -3.9757e+00, -4.3697e+00, -2.1532e+00,  4.6556e-01,\n",
      "         -3.7786e+00, -2.5181e+00, -1.6161e+00, -5.4781e-01,  2.0581e+00,\n",
      "         -2.4298e+00,  4.5775e-01, -3.3674e+00, -4.8193e+00, -6.4687e-02,\n",
      "         -2.7939e+00, -4.4103e+00,  2.0397e+00, -3.7749e+00, -5.7605e+00,\n",
      "         -7.5245e+00, -5.8051e-01, -2.5598e-01,  2.4855e+00, -3.9676e-01,\n",
      "         -1.9775e+00, -4.7999e+00, -8.0206e-01,  1.6157e+00, -4.8960e+00,\n",
      "         -4.3483e+00, -1.9582e+00,  6.5417e-01, -3.7090e+00, -2.8134e+00,\n",
      "         -1.2135e+00, -3.6640e+00,  5.2632e-01, -6.5845e+00,  3.5192e-01,\n",
      "         -4.4364e+00, -4.2635e+00, -4.1212e+00, -1.6345e+00, -3.7908e+00,\n",
      "          2.5664e+00, -3.0116e+00,  1.5586e+00, -2.6024e+00,  3.0985e+00,\n",
      "         -1.1773e+00, -2.5731e+00,  5.6009e-01, -1.2689e+00, -4.0011e-01,\n",
      "          9.1006e-02,  1.8919e+00, -1.7025e+00,  1.3037e+00,  4.3101e-01,\n",
      "         -2.0615e+00,  4.3259e+00,  5.7910e-01, -4.5964e+00,  4.5855e+00,\n",
      "          5.4271e-02, -1.7018e+00, -3.0466e-02, -8.6442e+00, -2.0079e+00,\n",
      "         -3.2840e-01,  1.8498e+00,  2.6263e+00, -1.0429e+00, -4.5236e+00,\n",
      "          1.1600e+00,  3.8496e+00, -4.0500e+00, -9.4227e-01, -3.9373e-01,\n",
      "         -1.5486e+00,  7.2589e-01, -1.6534e+00,  1.6223e+00, -8.2222e-01,\n",
      "          1.4485e+00, -1.6127e+00,  7.9693e-01,  3.0131e+00, -1.1712e+00,\n",
      "          4.4750e-02,  3.0340e+00, -5.5422e+00, -2.2338e+00, -1.1508e+00,\n",
      "         -1.5073e+00,  1.8086e+00, -2.7878e+00,  1.3329e-02, -3.7399e+00,\n",
      "         -1.5604e+00, -2.3859e+00,  1.4577e+00, -1.4933e+00, -2.2358e+00,\n",
      "         -2.3759e+00, -4.2478e-01, -4.2596e+00,  3.8758e-01, -1.2770e-01,\n",
      "         -6.2832e+00, -1.3813e+00, -5.5268e-02, -1.0065e+00, -4.2222e-01,\n",
      "         -1.1220e+00, -3.2774e-01, -1.8750e+00,  1.4989e-01, -2.6961e+00,\n",
      "         -2.8597e+00, -3.4103e+00, -1.7666e-01,  3.1446e+00,  1.6694e-01,\n",
      "         -3.5385e+00, -5.9723e+00, -7.7265e-02, -3.3690e+00, -1.3601e-01,\n",
      "         -8.6485e-01,  1.2254e+00,  1.1845e+00, -4.1984e+00, -2.5921e+00,\n",
      "         -1.7870e+00, -5.1281e-01,  2.1832e+00, -1.7719e-01,  2.2097e+00,\n",
      "         -2.6439e+00, -5.3538e-01,  2.9203e+00, -4.0928e-02, -1.8398e+00,\n",
      "          3.4457e+00,  5.5187e-01, -8.0450e-01, -8.3029e-01,  4.2574e+00,\n",
      "         -3.7449e+00, -1.4908e+00, -4.3196e+00, -3.0107e+00, -1.1151e+00,\n",
      "         -5.6080e+00, -2.0601e+00,  4.3291e+00, -1.1541e+00, -3.8401e+00,\n",
      "          1.7594e-01,  5.3892e+00, -1.5263e+00, -4.1831e+00, -2.7086e-01,\n",
      "          2.3661e+00,  2.2270e-01, -9.4921e-01, -1.6110e+00, -1.2479e+00,\n",
      "         -3.4468e+00, -2.1748e+00, -2.3233e+00, -6.8395e-01, -9.5563e-01,\n",
      "          6.2737e+00, -3.9921e-01, -2.3549e-01, -3.2353e-01,  5.1004e-01,\n",
      "         -8.7500e-01,  1.0997e+00, -4.2022e+00, -5.3403e+00,  3.8746e+00,\n",
      "          3.1967e+00,  1.0185e-01,  2.0000e+00,  2.7309e+00, -4.1979e+00,\n",
      "          2.4381e+00, -1.1786e+00, -4.0545e+00,  2.5223e+00, -3.6773e+00,\n",
      "         -5.4304e-01,  1.6663e+00, -4.1348e+00, -1.9970e+00, -6.7133e+00,\n",
      "          6.9305e-01, -3.1358e+00,  1.9978e+00,  4.1081e+00, -1.7941e+00,\n",
      "          2.1963e+00, -1.8842e+00,  7.6489e-01, -3.4608e+00, -9.7440e-01,\n",
      "         -3.8357e+00, -3.3476e+00, -7.5151e-01, -1.0475e+00,  3.1154e+00,\n",
      "         -9.7704e-01, -4.8304e+00, -3.4226e+00, -2.1858e+00, -3.6400e+00,\n",
      "         -1.9783e+00,  3.8931e-01, -3.6464e+00,  3.9159e-01, -4.4238e+00,\n",
      "         -1.1172e+00,  6.5820e-01, -8.3991e-01,  6.0266e-01, -7.7480e-01,\n",
      "         -1.8330e+00,  1.5744e+00,  2.9139e+00, -2.6004e+00,  5.2023e-01,\n",
      "         -5.3534e-01, -1.9204e+00,  2.3216e+00,  8.3138e-01, -7.5773e-01,\n",
      "          3.5678e+00, -1.3029e+00,  1.0747e+00, -1.0778e+00, -2.5609e+00,\n",
      "         -4.8354e+00, -4.5476e+00,  6.6143e-01,  1.0678e+00,  2.6779e+00,\n",
      "         -2.5462e+00, -1.2142e+00, -2.1056e+00, -8.8277e-02, -2.1291e+00,\n",
      "         -1.7224e+00, -1.1810e+00,  2.6162e+00, -1.2109e+00,  2.2584e+00,\n",
      "         -1.1926e+00,  7.1009e-01,  1.7042e+00, -4.5195e+00, -2.5022e+00,\n",
      "         -4.0505e+00,  3.0354e+00, -8.8182e-01, -3.2965e+00,  3.2258e+00,\n",
      "         -6.3060e-01,  8.8420e-01, -4.8224e+00, -2.1356e+00,  2.1651e+00,\n",
      "          3.3078e-01,  3.4258e-01, -1.0403e+00,  2.3919e+00, -2.2681e+00,\n",
      "          1.6829e+00,  6.2353e-02, -5.6294e+00, -6.5709e-03,  8.1990e-01,\n",
      "         -5.4628e+00, -1.1387e-01, -4.2916e+00, -7.6615e-01,  1.8140e+00,\n",
      "          2.5486e+00, -9.3190e-01, -7.2394e-02,  1.0454e-01, -3.8224e+00,\n",
      "         -1.9305e-01, -6.6647e-01, -2.6461e+00, -4.3505e+00, -1.1309e+00,\n",
      "          5.6407e-01, -1.4266e-01,  2.6652e-01,  1.5061e+00, -3.5130e+00,\n",
      "         -1.1322e+00,  2.4659e-01,  2.0793e+00, -7.3541e-01,  5.6644e-01,\n",
      "          4.4603e+00, -7.0219e-01, -4.1737e+00, -2.2037e+00,  4.5383e-01,\n",
      "          1.5862e+00, -1.9619e+00, -5.9359e-01, -2.3521e+00, -1.2254e+00,\n",
      "          1.7135e+00, -3.9016e+00, -3.5181e+00,  4.6154e-01,  9.1856e-01,\n",
      "         -2.5400e+00,  3.8199e-01,  2.4546e+00, -4.5644e+00, -5.6578e+00,\n",
      "          1.5995e+00, -1.4542e+00, -3.0382e+00,  1.0294e+00, -2.9999e+00,\n",
      "          1.2243e+00, -2.3012e+00, -2.4554e+00, -3.3392e+00, -6.1460e+00,\n",
      "         -4.0224e+00,  2.3777e-01, -4.6247e+00, -5.3142e-01,  1.4613e+00,\n",
      "         -8.7516e-01, -4.6541e+00, -2.5178e-01,  1.2294e+00, -1.9264e+00,\n",
      "          5.2139e-01, -1.7320e+00, -1.3176e+00, -3.5926e+00,  4.7973e-01,\n",
      "         -2.9564e+00, -6.5050e-01, -9.0519e-02, -1.7825e+00, -1.3802e+00,\n",
      "         -3.4082e+00,  8.5889e-01, -3.4657e+00,  1.4572e+00,  1.9854e+00,\n",
      "         -6.0396e+00, -2.9725e+00,  7.0111e+00,  2.4042e+00,  2.1980e+00,\n",
      "         -3.9049e+00, -2.0929e+00,  2.0487e-02, -1.5064e+00,  2.0189e+00,\n",
      "          1.5089e+00,  3.1503e+00, -9.2717e-02, -3.4496e-01, -1.0348e+00,\n",
      "         -4.5264e+00, -1.5325e+00,  3.8578e-01,  6.0073e-01, -1.9119e+00,\n",
      "         -5.0645e+00,  1.1068e+00, -1.6413e-01,  4.1328e+00,  1.8312e+00,\n",
      "          3.1563e+00,  2.3882e+00,  5.7670e-02,  9.6443e-01,  3.5164e+00,\n",
      "         -3.2524e-01,  1.5230e+00,  7.0298e-01, -5.0361e-02,  1.4544e+00,\n",
      "          2.9322e+00,  1.2154e-01,  5.3914e+00,  3.3377e+00,  4.1869e+00,\n",
      "          3.2296e+00,  3.3163e+00,  6.2030e+00,  2.4342e+00, -1.9602e+00,\n",
      "          4.0106e+00, -8.0333e-01,  6.5956e+00, -1.1392e+00,  2.2492e+00,\n",
      "          4.7361e+00,  3.6871e-01, -2.8298e-01,  2.3329e+00,  1.4934e+00,\n",
      "         -7.5079e-01, -1.4490e+00,  4.4534e+00, -4.4835e+00, -1.5599e+00,\n",
      "          7.4050e-01, -9.0904e-01,  3.2261e+00,  2.7841e+00,  1.1413e+00,\n",
      "          2.0040e+00,  6.1263e-01,  4.9921e-01,  1.4957e+00,  4.0446e-01,\n",
      "          1.0147e-01,  3.4531e-01,  1.1840e-01,  8.0750e+00, -1.1397e+00,\n",
      "          1.3780e+00, -1.0306e+00, -6.3537e-01, -2.7285e-02, -1.7578e-01,\n",
      "          4.9312e+00,  3.2953e-01, -3.3956e+00,  2.8357e+00, -1.4560e+00,\n",
      "          3.1802e+00,  3.8004e+00,  3.4940e+00,  2.0482e+00,  5.7372e+00,\n",
      "          1.3265e+00,  9.1549e+00,  6.4710e+00,  3.8046e+00,  1.0951e+01,\n",
      "          4.0573e+00,  5.4944e+00,  5.8750e+00,  3.4299e+00,  1.6302e-01]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([ 1, 27, 29, 26, 42])\n"
     ]
    }
   ],
   "source": [
    "# CHECK RESULT\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "index = 1\n",
    "\n",
    "check_model.eval()\n",
    "\n",
    "file = './Imagenet/' + str(index) + '.jpg'\n",
    "  \n",
    "img = Image.open(file)\n",
    "img_tensor = preprocess(img)\n",
    "img_tensor.unsqueeze_(0)\n",
    "#print(img_tensor.shape)\n",
    "#print(img_tensor)\n",
    "\n",
    "start = time.time()\n",
    "outputs = check_model(Variable(img_tensor))\n",
    "end = time.time()\n",
    "print('Elapsed Time: ' + str(end-start))\n",
    "print(outputs.shape)\n",
    "print(outputs)\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "softmax_out = softmax(outputs)\n",
    "#print(softmax_out.shape)\n",
    "#print(softmax_out)\n",
    "\n",
    "print(softmax_out.topk(5)[1][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
